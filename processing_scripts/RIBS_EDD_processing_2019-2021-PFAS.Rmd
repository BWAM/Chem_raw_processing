---
title: "RIBS_EDD_processing"
author: "Gavin Lemley"
date: "January 11, 2019"
output: html_document
---

Load libraries, find the R-project root directory, and specify input/output files.
```{r}
library(tidyverse)
library(readxl)
root.dir <- rprojroot::find_root("Chem_raw_processing.Rproj")

##### User-defined variables #####

proj_name <- "pfas_2019-2021"    # use only lowercase with underscores as spaces"
# Need to manually create folders with this name in each "input" and "output" folders
proj_year <- "2021"

##################################


input.path <- file.path(root.dir, "data_input", proj_year, proj_name)
# input.path <- file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - TestAmerica/2021/lab_reports/pfas_prioritywaters/")
output.path <- file.path(root.dir, "data_output", proj_year, proj_name)

output.filename <- paste0("chem_preqaqc_JOIN-", proj_name, "_", Sys.Date(), ".csv")
output.sample.filename <- paste0("chem_preqaqc_SAMPLE-", proj_name, "_", Sys.Date(), ".csv")
output.result.filename <- paste0("chem_preqaqc_RESULT-", proj_name, "_", Sys.Date(), ".csv")
# output.batch.filename <- paste0("chem_preqaqc_BATCH-", proj_name, "_", Sys.Date(), ".csv")

#Specify sites reference table
# sites.master <- read_excel("C:/Users/gmlemley/New York State Office of Information Technology Services/SMAS - Streams Data Modernization/Cleaned Files/Final_Sites_ITS/20210608_S_Site_all_fields.xlsx") %>% 
#   rename(SITE_ID = SITE_HISTORY_ID)

# Routine sites list
sites.routine <- read_excel(file.path(root.dir, "data_input/site_tables/RIBS_ROUTINE_SITES_REGION_INFO_2020-09-14.xlsx")) %>% 
  rename(SITE_ID = "SBU ID") %>% 
  select(SITE_ID)

# Methods eval sites list
sites.metheval <- read_csv(file.path(root.dir, "data_input/site_tables/2021_methods_eval_sites.csv")) %>% 
  rename(SITE_ID = site_id) %>% 
  select(SITE_ID)

# PFAS PW sites list
sites.pfaspw <- read_csv(file.path(root.dir, "data_input/site_tables/2021_pfas_pw_sites.csv")) %>% 
  rename(SITE_ID = SiteID) %>% 
  select(SITE_ID)

#2021 draft sites list
# sites.2021 <- read_excel(file.path(root.dir, "data_input/site_tables/c20211006_SEI_Simplified_W_Adjusted_ID_created20212018.xlsx")) %>% 
#   rename(SITE_ID = SEIH_EVENT_SMAS_HISTORY_ID) %>% 
#   select(SITE_ID) %>% 
#   unique()
# sites.2021.v2 <- read_excel(file.path(root.dir, "data_input/site_tables/Proposed_Sites_Sampled_2021_w_Adjusted_Site_ID_created_20211026.xlsx")) %>% 
#   rename(SITE_ID = SITE_HISTORY_ID) %>% 
#   select(SITE_ID) %>% 
#   unique()

#2021 Mohawk sites (not in above list yet)
# sites.mo.2021 <- read_excel(file.path(root.dir, "data_input/site_tables/Mohawk_2021_site_list.xlsx")) 

# sites.master <- bind_rows(sites.routine, sites.2021, sites.mo.2021)
sites.master <- bind_rows(sites.routine, sites.metheval, sites.pfaspw) %>% 
  distinct()

```

Main process
```{r}

# Initialize loop objects and variables 
folder_list <- list.files(path = input.path)
nfolder_list = length(folder_list)
RSfile_list <- list()
sample.file_list <- list()
result.file_list <- list()
# batch.file_list <- list()
i=1

message(paste0(nfolder_list, " EDDs present:\n"))

# Loop through each file (folder) present in folder_list
for (i in 1:nfolder_list){
  print(folder_list[i])
  input.i <- paste0(input.path, "/", folder_list[i])
  output.i <- file.path(root.dir, "data_output")

  temp_result <- read_excel(dir(input.i, full.names=T, pattern="EquNysdec.xls"), sheet = "TestResultQC_v4") %>% 
    rename(sys_sample_code = "#sys_sample_code") %>% 
    mutate(job_number = folder_list[i]) %>% 
    select(job_number, everything())

  temp_sample <- read_excel(dir(input.i, full.names=T, pattern="EquNysdec.xls"), sheet = "Sample_v4") %>% 
    rename(data_provider = "#data_provider") %>% 
    mutate(job_number = folder_list[i]) %>% 
    select(job_number, everything())
 
  ##########  Generating site IDs  ##########  
  
  # Duplicate sample_name field and convert all spaces to dashes before pulling site IDs ###
  temp_sample <- temp_sample %>% 
    mutate(sample_name_temp = sample_name) %>% 
    mutate(sample_name_temp = sub(" ", "-", sample_name_temp))
  
  ### Generate site IDs for all non-lab sample data by pulling info from sample_name before 3rd "-".
  temp_sample$SITE_ID <- ifelse(temp_sample$sample_source %in% "Field" | temp_sample$sample_type_code %in% "TB",
                               sub("^(([^-]*-){2}[^-]*).*","\\1" , temp_sample$sample_name_temp), NA)

  # Delete temp column
  temp_sample <- temp_sample %>% 
    select(-sample_name_temp)
  
  
  ############## DATA CORRECTIONS #################
  
  # Recode fields for FB samples due to inconsistencies with TestAmerica data and differences with how ALS codes our QC samples (which our tables and metadata was built from)
  temp_sample$sample_matrix_code <- ifelse(grepl("-FB",temp_sample$sample_name),"WS",temp_sample$sample_matrix_code)
  temp_sample$sample_type_code <- ifelse(grepl("-FB",temp_sample$sample_name),"N",temp_sample$sample_type_code)
  temp_sample$sample_source <- ifelse(grepl("-FB",temp_sample$sample_name),"Field",temp_sample$sample_source)
  # Recode sample_source field for MS and MSDs as "Lab" instead of "Field" to be consistent with ALS data and our metadata
  temp_sample$sample_source <- ifelse(grepl("MS|MSD",temp_sample$sample_type_code),"Lab",temp_sample$sample_source)
  temp_sample$sample_matrix_code <- ifelse(grepl("MS|MSD",temp_sample$sample_type_code),"WS",temp_sample$sample_matrix_code)

  # Correct 3 samples falsely noted as "FB" sample_type_code. Checked against COCs and QC schedules.
  temp_sample$sample_matrix_code <- ifelse(grepl("13-LHUD-125.8-102219-W-20191022",temp_sample$sys_sample_code),"WS",temp_sample$sample_matrix_code)
  temp_sample$sample_matrix_code <- ifelse(grepl("14-WDEL-16.2-102319-W-20191023",temp_sample$sys_sample_code),"WS",temp_sample$sample_matrix_code)
  temp_sample$sample_matrix_code <- ifelse(grepl("07-OSWE-5.2-08172021-W",temp_sample$sys_sample_code),"WS",temp_sample$sample_matrix_code)
  temp_sample$sample_type_code <- ifelse(grepl("13-LHUD-125.8-102219-W-20191022",temp_sample$sys_sample_code),"N",temp_sample$sample_type_code)
  temp_sample$sample_type_code <- ifelse(grepl("14-WDEL-16.2-102319-W-20191023",temp_sample$sys_sample_code),"N",temp_sample$sample_type_code)
  temp_sample$sample_type_code <- ifelse(grepl("07-OSWE-5.2-08172021-W",temp_sample$sys_sample_code),"N",temp_sample$sample_type_code)

  ##### Locate and code QAQC samples #####
    
  # Set Site ID to 00-QAQC-0.0 for internal lab samples
  temp_sample$SITE_ID <- ifelse(temp_sample$sample_matrix_code %in% "WQ", "00-QAQC-0.0", temp_sample$SITE_ID)
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_matrix_code %in% "WQ", "LAB_INTERNAL", NA)

  # Populate DEC_sample_type for FB samples. (only used in Routine data, where mercury samples exist)
  temp_sample$DEC_sample_type <- ifelse(grepl("-FB",temp_sample$sample_name),"FB", temp_sample$DEC_sample_type)

  # Populate DEC_sample_type for duplicate samples.
      # Accounts for different DUP variants ("-DUP"", " DUP", "WSDUP", "WDUP", and upper/lowercase instances)
  # temp_sample$DEC_sample_type <- ifelse(grepl("-[Ss][Ee][Qq]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  # temp_sample$DEC_sample_type <- ifelse(grepl(" [Ss][Ee][Qq]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  # temp_sample$DEC_sample_type <- ifelse(grepl("WS[Ss][Ee][Qq]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  # temp_sample$DEC_sample_type <- ifelse(grepl("W[Ss][Ee][Qq]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  # temp_sample$DEC_sample_type <- ifelse(grepl("[Ss][Ee][Qq]_",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  
  # Populate DEC_sample_type for N_DUPPARENT cells by locating DUP samples and finding parent sample by removing DUP code. 
  # Updated 4/7/21 to perform on sys_sample_code instead of sample_name in case reanalyses present (was causing to fail).
  # dup.vec <- temp_sample$sys_sample_code[grepl("-[Ss][Ee][Qq]", temp_sample$sys_sample_code)]
  # parent.vec <- gsub("-[Ss][Ee][Qq]", "", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  # 
  # dup.vec <- temp_sample$sys_sample_code[grepl(" [Ss][Ee][Qq]", temp_sample$sys_sample_code)]
  # parent.vec <- gsub(" [Ss][Ee][Qq]", "", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  # 
  # dup.vec <- temp_sample$sys_sample_code[grepl("WS[Ss][Ee][Qq]", temp_sample$sys_sample_code)]
  # parent.vec <- gsub("WS[Ss][Ee][Qq]", "WS", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  # 
  # dup.vec <- temp_sample$sys_sample_code[grepl("W[Ss][Ee][Qq]", temp_sample$sys_sample_code)]
  # parent.vec <- gsub("W[Ss][Ee][Qq]", "W", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  # 
  # dup.vec <- temp_sample$sys_sample_code[grepl("[Ss][Ee][Qq]_", temp_sample$sys_sample_code)]
  # parent.vec <- gsub("[Ss][Ee][Qq]_", "_", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)

  # Populate remaining DEC_sample_type NAs for field data with "N" for normal samples (assumes all remaining NAs are normal samples).
  temp_sample$DEC_sample_type <- ifelse(is.na(temp_sample$DEC_sample_type),"N",temp_sample$DEC_sample_type)

  # Count number of each FIELD sample type identified and print
  count.Normal <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("^N$", temp_sample$DEC_sample_type)])  
  message(paste0(count.Normal," N"))
  # count.N_DUPPARENT <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("N_DUPPARENT", temp_sample$DEC_sample_type)])  
  # message(paste0(count.N_DUPPARENT," N_DUPPARENT"))
  # count.DUP <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("^DUP$", temp_sample$DEC_sample_type)])  
  # message(paste0(count.DUP," DUP"))
  # count.EB <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("^EB$", temp_sample$DEC_sample_type)])  
  # message(paste0(count.EB," EB"))
  count.FB <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("^FB$", temp_sample$DEC_sample_type)])  
  message(paste0(count.FB," FB\n"))
  
  # count.MS <- length(grep("^MS$", temp_sample$sample_type_code))  
  # message(paste0(count.MS," MS (including lab MSs)\n"))
  
  # Check if equal number of DUP and N_DUPPARENT codes assigned. Stop script if not.
  # if(identical(count.DUP,count.N_DUPPARENT) == FALSE){
  #   stop("    DUP and N_DUPPARENT counts do not match (script stopped)")
  # }
    
  ##### Merge sample and result files #####
    # Must merge by sys_sample_code and not sample_name in order to appropriately associate MS, dissolved samples (sometimes "Diss" or "S" added to end of sys_sample_code), and other lab samples with appropriate results.
  
  temp_RSmerge <- merge(temp_sample,temp_result,by="sys_sample_code", all=TRUE) %>% 
    select(-job_number.y) %>% 
    rename(job_number = job_number.x)

  filenm <- file.path(output.i,
                      paste(folder_list[i],"_RSmerge.csv", sep=""))

  if ((nrow(temp_result)) < (nrow(temp_RSmerge))) {
    stop('SCRIPT STOPPED: Extra records created in merge. Check EDD for errors.')
  }
  if ((nrow(temp_result)) > (nrow(temp_RSmerge))) {
    stop('SCRIPT STOPPED: Not enough records created with merge. Check for errors.')
  }

  # Create name using EDD and added suffix, and assign to current data frame
  mergenm <- paste0(folder_list[i], "_RSmerge")
  mergefile <- assign(mergenm, temp_RSmerge)
  
  # Do the same for sample and result file data (used for assessing samples present and counting sample totals)
  mergenm.sample <- paste0(folder_list[i], "_Samplemerge")
  mergefile.sample <- assign(mergenm.sample, temp_sample)
  mergenm.result <- paste0(folder_list[i], "_Resultmerge")
  mergefile.result <- assign(mergenm.result, temp_result)
  # mergenm.batch <- paste0(folder_list[i], "_Batchmerge")
  # mergefile.batch <- assign(mergenm.batch, temp_batch)
  
  #Add current data frame to the list of all dataframes
  RSfile_list[[i]] <- mergefile
  sample.file_list[[i]] <- mergefile.sample
  result.file_list[[i]] <- mergefile.result
  # batch.file_list[[i]] <- mergefile.batch
  
  rm(mergefile, mergefile.sample, mergefile.result)
  
  # Export each merged EDD as CSVs (use for troubleshooting)
  # write.table(temp_RSmerge, file=filenm,sep=",", row.names = FALSE)
}

#Bind all data frames (merged sample-result files) into one
RIBSdata.ALL = do.call(rbind, RSfile_list)
RIBSdata.sample = do.call(rbind, sample.file_list)
RIBSdata.result = do.call(rbind, result.file_list)
# RIBSdata.batch = do.call(rbind, batch.file_list)

# Move new Site ID and DEC Sample Type columns to beginning of data frame
RIBSdata.ALL <- RIBSdata.ALL %>% 
  select(SITE_ID, DEC_sample_type, everything())
RIBSdata.sample <- RIBSdata.sample %>% 
  select(SITE_ID, DEC_sample_type, everything())


# List unqique sampling dates to verify all present
sample.dates <- unique(as.Date(RIBSdata.sample$sample_date[RIBSdata.sample$sample_source == "Field"], "%m/%d/%Y %H:%M:%S"))
# sample.dates <- unique(as.Date(RIBSdata.sample$sample_date[RIBSdata.sample$sample_source == "Field"], "%Y-%m-%d %H:%M:%S"))
message(paste0(length(sample.dates)," unique sample dates present:\n"))
cat(as.character(sort(sample.dates)), sep = "\n")



### Summarize sample counts to compare to COCs (ensure sure all codes assigned appropriately).
# Rebuilt code code block below when expanded code assignments to lab samples

totalcount.Normal <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("^N$", RIBSdata.sample$DEC_sample_type)])
# totalcount.DUP <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("^DUP$", RIBSdata.sample$DEC_sample_type)])
# totalcount.N_DUPPARENT <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("N_DUPPARENT", RIBSdata.sample$DEC_sample_type)])
# totalcount.EB <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("^EB$", RIBSdata.sample$DEC_sample_type)])
totalcount.FB <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("^FB$", RIBSdata.sample$DEC_sample_type)])     # FB only present in Routine Network data
totalcount.MS <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Lab" & RIBSdata.sample$sample_type_code == "MS"]) 
totalcount.MSD <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Lab" & RIBSdata.sample$sample_type_code == "SD"]) 
totalcount.LR <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Lab" & RIBSdata.sample$sample_type_code == "LR"]) 

message(paste0("\nTotal samples identified (+1 for each subcontracted sample :)\n", 
               totalcount.Normal, " N\n", 
               # totalcount.N_DUPPARENT, " N_DUPPARENT\n", 
               # totalcount.DUP, " DUP\n",  
               # totalcount.EB, " EB\n", 
               totalcount.FB, " FB (should only be present for Routine)\n" ,
               totalcount.MS, " Matrix Spikes (not run on all params for all samples)\n",
               totalcount.MSD, " Matrix Spike Dups\n",
               totalcount.LR, " Lab replicates\n"
               ))

# if(totalcount.DUP == 0){warning(paste0("    WARNING: NO DUPLICATES PRESENT\n"))}
# if(totalcount.N_DUPPARENT == 0){warning(paste0("    WARNING: NO DUP PARENTS PRESENT\n"))}
# if(totalcount.EB == 0){warning(paste0("    WARNING: NO EBs PRESENT\n"))}
if(totalcount.FB == 0){warning(paste0("    WARNING: NO FBs PRESENT (only required for Routine data)\n"))}
# if(totalcount.FB > 0){warning(paste0("    WARNING: FBs PRESENT (only should be present for Routine data)\n"))}
if(totalcount.MS == 0){warning(paste0("    WARNING: NO MSs PRESENT\n"))}

# Check for ALS reanalyses (could mean duplicate results for one sample/param combination)
reanalyses <- RIBSdata.ALL$sys_sample_code[(endsWith(RIBSdata.ALL$sys_sample_code,"RE"))]
if(length(reanalyses) > 0){
  message("\nWARNING: Reanalyses present (possible duplicate results for one sample/param combination): \n\n",cat(reanalyses, sep = "\n"))
} 

```

See if matches for generated site IDs exist in master sites table. If mismatches are found, process into code for copy/pasting into next chunk for correcting. 2nd instance of each site ID (after the ~) to be corrected manually after pasting next chunk.
# Use RIBSdata.sample (sample list only) to help troubleshoot site ID mismatch issues.
# Use space at top of this chunk if edits needed before matching site IDs
```{r echo=TRUE}
########################


# List unique site IDs generated and creat match/mismatch lists
siteids.present <- unique(RIBSdata.ALL$SITE_ID[!is.na(RIBSdata.ALL$SITE_ID)])
siteids.mismatch <- siteids.present[!(siteids.present %in% sites.master$SITE_ID)]
siteids.match <- siteids.present[(siteids.present %in% sites.master$SITE_ID)]

# See if mismatches exist. If so (else), prepare code for renaming mismatched site IDs and print to console to be pasted into the chunk below. 2nd instance of each site ID (after the ~) to be corrected manually after pasting in chunk below.
if (length(siteids.mismatch) == 0 & length(siteids.match) > 0) {
  message("Match found for all ", length(siteids.match), " site IDs.")
} else{
  message(length(siteids.present)," unique site IDs generated from sample IDs\n",length(siteids.match), " matches found, ", length(siteids.mismatch), " mismatch(es):\n")
  siteids.mismatch.code <- paste0("    SITE_ID == '",siteids.mismatch,"' ~ '",siteids.mismatch,"',")
  cat(siteids.mismatch.code,sep="\n")
}

# message("\n\nUnique site ID's present in sys_loc_code field (as transcribed by ALS)")
# sort(unique(RIBSdata.sample$sys_loc_code))

```

SITE_ID and data corrections:
Run as many times as needed until all corrected.
User manually corrects site IDs that couldn't be located in master sites table by pasting the output code from above and correct the 2nd instance of each site ID (after the ~).
```{r correct_data,echo=TRUE}
RIBSdata.ALL_corr <- RIBSdata.ALL %>% 
  mutate(SITE_ID_corr = case_when(
    SITE_ID == '00-QAQC-0.0' ~ '00-QAQC-0.0',
    SITE_ID == '02-CHAD-2.2' ~ '02-CHAD-1.9',
    SITE_ID == '10-SARA-0.4' ~ '10-SARA-0.3',
    SITE_ID == '13-ROND-9.9' ~ '13-ROND-9.2',
    SITE_ID == '17-KENF_Ta_0.2-04212021' ~ '17-KENF_Ta-0.2',
    SITE_ID == '14-NEVR-1.3' ~ '14-NEVR-8.9',
    SITE_ID == '17-BLND_TB-2.0' ~ '17-BLND_Tb-2.0',
    SITE_ID == '17-KENE_0.3-08242021' ~ '17-KENE-0.3',
    SITE_ID == '17-KENF_TA_0.2-024' ~ '17-KENF_Ta-0.2',
    SITE_ID == '17-KENF_TA_0.2-08242021' ~ '17-KENF_Ta-0.2',
    SITE_ID == '17-KENF_TA-2.0' ~ '17-KENF_Ta-0.2',
    TRUE ~ SITE_ID
  )
  ) %>% 
  mutate(SITE_ID_CORR_IND = if_else(SITE_ID_corr == SITE_ID, "N", "Y")) %>% 
  select(-SITE_ID) %>% 
  select(SITE_ID_corr, SITE_ID_CORR_IND, everything()) %>% 
  rename(SITE_ID = SITE_ID_corr)

# Do the same for the sample file

RIBSdata.sample_corr <- RIBSdata.sample %>% 
  mutate(SITE_ID_corr = case_when(
    SITE_ID == '00-QAQC-0.0' ~ '00-QAQC-0.0',
    SITE_ID == '02-CHAD-2.2' ~ '02-CHAD-1.9',
    SITE_ID == '10-SARA-0.4' ~ '10-SARA-0.3',
    SITE_ID == '13-ROND-9.9' ~ '13-ROND-9.2',
    SITE_ID == '17-KENF_Ta_0.2-04212021' ~ '17-KENF_Ta-0.2',
    SITE_ID == '14-NEVR-1.3' ~ '14-NEVR-8.9',
    SITE_ID == '17-BLND_TB-2.0' ~ '17-BLND_Tb-2.0',
    SITE_ID == '17-KENE_0.3-08242021' ~ '17-KENE-0.3',
    SITE_ID == '17-KENF_TA_0.2-024' ~ '17-KENF_Ta-0.2',
    SITE_ID == '17-KENF_TA_0.2-08242021' ~ '17-KENF_Ta-0.2',
    SITE_ID == '17-KENF_TA-2.0' ~ '17-KENF_Ta-0.2',
    TRUE ~ SITE_ID
    )
  ) %>% 
  mutate(SITE_ID_CORR_IND = if_else(SITE_ID_corr == SITE_ID, "N", "Y")) %>% 
  select(-SITE_ID) %>% 
  select(SITE_ID_corr, SITE_ID_CORR_IND, everything()) %>% 
  rename(SITE_ID = SITE_ID_corr)
  
# Check again for mismatches and print
siteids.present.corr <- unique(RIBSdata.ALL_corr$SITE_ID[!is.na(RIBSdata.ALL_corr$SITE_ID)])
siteids.mismatch2 <- siteids.present.corr[!(siteids.present.corr %in% sites.master$SITE_ID)]
siteids.match2 <- siteids.present.corr[(siteids.present.corr %in% sites.master$SITE_ID)]

if(length(siteids.mismatch2 > 0)){
  message("The following ", length(siteids.mismatch2), " sites were still not matched:")
  cat(siteids.mismatch2,sep="\n")
} else{
  message("All sites matched!")
}
```

```{r Completeness checks}

# Apply project names based on job number
joblist <- read_excel(file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - TestAmerica/2021/job_list", "2021_TestAmerica_joblists_ALL.xlsx"), sheet = "ALL_projects") %>% 
  select(JobID, DEC_project, DEC_team) %>% 
  rename(job_number = JobID) %>% 
  distinct(job_number, .keep_all = TRUE)

# Return missing EDDs from project list
missing.joblist <- joblist %>% 
  filter(!job_number %in% RIBSdata.sample$job_number)

# Attache projet names by job #
sample.proj <- RIBSdata.sample_corr %>% 
  left_join(joblist) %>% 
  select(DEC_project, DEC_team, everything()) %>% 
  filter(sample_source %in% "Field")

# Split out projects to perform completeness checks
sample.ribs <- sample.proj %>% 
  filter(grepl("*Routine", DEC_project))

sample.ribs.2019 <- sample.ribs %>% 
  filter(grepl("2019", sample_date),
         sample_source %in% "Field"
         # DEC_sample_type %in% "N"
         ) 

sample.ribs.2021apr <- sample.ribs %>% 
  filter(grepl("2021-04", sample_date),
         sample_source %in% "Field"
         # DEC_sample_type %in% "N"
         ) 

sample.ribs.2021aug <- sample.ribs %>% 
  filter(grepl("2021-08", sample_date),
         sample_source %in% "Field"
         # DEC_sample_type %in% "N"
         ) 

sample.meth <- sample.proj %>% 
  filter(grepl("*Methods", DEC_project))

sample.pfaspw.apr <- sample.proj %>% 
  filter(grepl("*Priority", DEC_project),
         grepl("2021-04", sample_date))
sample.pfaspw.aug <- sample.proj %>% 
  filter(grepl("*Priority", DEC_project),
         grepl("2021-08", sample_date))



# Return missing sites from Routine 2021 sampling
missing.2021apr <- sites.routine %>% 
  filter(!SITE_ID %in% sample.ribs.2021apr$SITE_ID)
missing.2021aug <- sites.routine %>% 
  filter(!SITE_ID %in% sample.ribs.2021aug$SITE_ID)

# Return missing sites from Methods Eval sampling
missing.metheval <- sites.metheval %>% 
  filter(!SITE_ID %in% sample.meth$SITE_ID)

# Return missing sites from PFAS PW sampling
missing.pfaspw.apr <- sites.pfaspw %>% 
  filter(!SITE_ID %in% sample.pfaspw.apr$SITE_ID)
missing.pfaspw.aug <- sites.pfaspw %>% 
  filter(!SITE_ID %in% sample.pfaspw.aug$SITE_ID)
```


Apply project names, make final edits, and export final tables 
```{r}

joblist <- joblist %>% 
  select(-DEC_team)

# Also Recode Methods evaluation sample types as ME (normal sample) and MEFB (field blanks) in order to differentiate from Routine CEC samples.
RIBSdata.ALL_corr.proj <- RIBSdata.ALL_corr %>% 
  left_join(joblist) %>% 
  select(DEC_project, everything()) %>% 
  mutate(DEC_sample_type = ifelse(grepl("*Methods", DEC_project) & DEC_sample_type == "N","ME", DEC_sample_type),
         DEC_sample_type = ifelse(grepl("*Methods", DEC_project) & DEC_sample_type == "FB","MEFB", DEC_sample_type))

RIBSdata.sample_corr.proj <- RIBSdata.sample_corr %>% 
  left_join(joblist) %>% 
  select(DEC_project, everything()) %>% 
  mutate(DEC_sample_type = ifelse(grepl("*Methods", DEC_project) & DEC_sample_type == "N","ME", DEC_sample_type),
         DEC_sample_type = ifelse(grepl("*Methods", DEC_project) & DEC_sample_type == "FB","MEFB", DEC_sample_type))


RIBSdata.ALL.meth_eval <- RIBSdata.ALL_corr.proj %>% 
  filter(grepl("*Methods", DEC_project))

RIBSdata.ALL.routine_cec <- RIBSdata.ALL_corr.proj %>% 
  filter(grepl("*Routine", DEC_project))

RIBSdata.ALL.pfaspw <- RIBSdata.ALL_corr.proj %>% 
  filter(grepl("*Priority", DEC_project))

# Export pre-joined tables (for data analysis)
write.csv(RIBSdata.ALL.meth_eval, file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - CECs/data/pfas", "methods_eval_ppcp_results_2021.csv"),row.names = FALSE)

# Export pre-joined tables (for data analysis)
write.csv(RIBSdata.ALL.routine_cec, file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - CECs/data/pfas", "routine_pfas_results_2019_2021.csv"),row.names = FALSE)

# Export pre-joined tables (for data analysis)
write.csv(RIBSdata.ALL.pfaspw, file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - CECs/data/pfas", "routine_ppcp_results_2019_2021.csv"),row.names = FALSE)


# Export sample and result (all project) for adding to database and running through QAQC if needed.

# # Export sample table
write.table(RIBSdata.sample_corr.proj, file= paste0(output.path,"/",output.sample.filename),sep=",", row.names = FALSE)

# # Export results table
write.table(RIBSdata.result, file= paste0(output.path,"/",output.result.filename),sep=",", row.names = FALSE)

# # Export full joined table
write.table(RIBSdata.ALL_corr.proj, file= paste0(output.path,"/",output.filename),sep=",", row.names = FALSE)


```

