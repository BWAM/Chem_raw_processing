---
title: "RIBS_EDD_processing"
author: "Gavin Lemley"
date: "January 11, 2019"
output: html_document
---

Load libraries, find the R-project root directory, and specify input/output files.
```{r}
library(tidyverse)
library(readxl)
root.dir <- rprojroot::find_root("Chem_raw_processing.Rproj")

##### User-defined variables #####

proj_name <- "PFAS_2019_2021"    # use only lowercase with underscores as spaces"
# Need to manually create folders with this name in each "input" and "output" folders
proj_year <- "2021"

##################################


# input.path <- file.path(root.dir, "data_input", proj_year, proj_name)
input.path <- file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - TestAmerica/2021/lab_reports/routine_pfas_2019_2021/")
output.path <- file.path(root.dir, "data_output", proj_year, proj_name)

output.filename <- paste0("chem_preqaqc_JOIN-", proj_name, "_", Sys.Date(), ".csv")
output.sample.filename <- paste0("chem_preqaqc_SAMPLE-", proj_name, "_", Sys.Date(), ".csv")
output.result.filename <- paste0("chem_preqaqc_RESULT-", proj_name, "_", Sys.Date(), ".csv")
# output.batch.filename <- paste0("chem_preqaqc_BATCH-", proj_name, "_", Sys.Date(), ".csv")

#Specify sites reference table
# sites.master <- read_excel("C:/Users/gmlemley/New York State Office of Information Technology Services/SMAS - Streams Data Modernization/Cleaned Files/Final_Sites_ITS/20210608_S_Site_all_fields.xlsx") %>% 
#   rename(SITE_ID = SITE_HISTORY_ID)

# Routine sites list
sites.routine <- read_excel(file.path(root.dir, "data_input/site_tables/RIBS_ROUTINE_SITES_REGION_INFO_2020-09-14.xlsx")) %>% 
  rename(SITE_ID = "SBU ID") %>% 
  select(SITE_ID)

#2021 draft sites list
# sites.2021 <- read_excel(file.path(root.dir, "data_input/site_tables/c20211006_SEI_Simplified_W_Adjusted_ID_created20212018.xlsx")) %>% 
#   rename(SITE_ID = SEIH_EVENT_SMAS_HISTORY_ID) %>% 
#   select(SITE_ID) %>% 
#   unique()
# sites.2021.v2 <- read_excel(file.path(root.dir, "data_input/site_tables/Proposed_Sites_Sampled_2021_w_Adjusted_Site_ID_created_20211026.xlsx")) %>% 
#   rename(SITE_ID = SITE_HISTORY_ID) %>% 
#   select(SITE_ID) %>% 
#   unique()

#2021 Mohawk sites (not in above list yet)
# sites.mo.2021 <- read_excel(file.path(root.dir, "data_input/site_tables/Mohawk_2021_site_list.xlsx")) 

# sites.master <- bind_rows(sites.routine, sites.2021, sites.mo.2021)
sites.master <- sites.routine

```

Main process
```{r}

# Initialize loop objects and variables 
folder_list <- list.files(path = input.path)
nfolder_list = length(folder_list)
RSfile_list <- list()
sample.file_list <- list()
result.file_list <- list()
# batch.file_list <- list()
i=1

message(paste0(nfolder_list, " EDDs present:\n"))

# Loop through each file (folder) present in folder_list
for (i in 1:nfolder_list){
  print(folder_list[i])
  input.i <- paste0(input.path, "/", folder_list[i])
  output.i <- file.path(root.dir, "data_output")

  # rename revised EDD filenames if they exist  # file.rename(file.path(input.i,"TestResultQC_v3 REV.txt"), file.path(input.i,"TestResultQC_v3.txt"))
  # file.rename(file.path(input.i,"TestResultQC_v3 rev2.txt"), file.path(input.i,"TestResultQC_v3.txt"))
  # file.rename(file.path(input.i,"TestResultQC_v3 rev3.txt"), file.path(input.i,"TestResultQC_v3.txt"))
  # file.rename(file.path(input.i,"Sample_v3 REV.txt"), file.path(input.i,"Sample_v3.txt"))
  # file.rename(file.path(input.i,"Sample_v3 rev2.txt"), file.path(input.i,"Sample_v3.txt"))
  # file.rename(file.path(input.i,"Sample_v3 rev3.txt"), file.path(input.i,"Sample_v3.txt"))
  # file.rename(file.path(input.i,"Batch_v3 REV.txt"), file.path(input.i,"Batch_v3.txt"))
  # file.rename(file.path(input.i,"Batch_v3 rev2.txt"), file.path(input.i,"Batch_v3.txt"))
  # file.rename(file.path(input.i,"Batch_v3 rev3.txt"), file.path(input.i,"Batch_v3.txt"))

  temp_result <- read_excel(dir(input.i, full.names=T, pattern="EquNysdec.xls"), sheet = "TestResultQC_v4") %>% 
    rename(sys_sample_code = "#sys_sample_code") %>% 
    mutate(job_number = folder_list[i]) %>% 
    select(job_number, everything())

  temp_sample <- read_excel(dir(input.i, full.names=T, pattern="EquNysdec.xls"), sheet = "Sample_v4") %>% 
    rename(data_provider = "#data_provider") %>% 
    mutate(job_number = folder_list[i]) %>% 
    select(job_number, everything())
 
  ##########  Generating site IDs  ##########  
  
  # Duplicate sample_name field and convert all spaces to dashes before pulling site IDs ###
  temp_sample <- temp_sample %>% 
    mutate(sample_name_temp = sample_name) %>% 
    mutate(sample_name_temp = sub(" ", "-", sample_name_temp))
  
  ### Generate site IDs for all non-lab sample data by pulling info from sample_name before 3rd "-".
  temp_sample$SITE_ID <- ifelse(temp_sample$sample_source %in% "Field" | temp_sample$sample_type_code %in% "TB",
                               sub("^(([^-]*-){2}[^-]*).*","\\1" , temp_sample$sample_name_temp), NA)

    ## Alternative method #2 to generating SITE_ID. Pulls string from before first underscore
    # temp_sample$SITE_ID <- ifelse(temp_sample$sample_matrix_code == "WS",
    #                            str_extract(temp_sample$sample_name_temp, "[^_]+"), NA)
    
  ## Alternative method #3 to generating SITE_ID. Pulls string from position after decimal (as expected in river mile). WOrks better for older data:
        ## DOES NOT WORK IF NO DECIMAL PRESENT (some site IDs use -001 as rivermile)
    # temp_sample$SITE_ID <- ifelse(temp_sample$sample_matrix_code == "WS",
    #                            substr(temp_sample$sample_name_temp, 1, as.numeric(gregexpr(pattern ='\\.',temp_sample$sample_name_temp)) + 1), NA)
  

  # Delete temp column
  temp_sample <- temp_sample %>% 
    select(-sample_name_temp)
  
  ############## DATA CORRECTIONS #################
  
  
  # Recode fields for FB samples due to inconsistencies with TestAmerica data and differences with how ALS codes our QC samples
  temp_sample$sample_matrix_code <- ifelse(grepl("-FB",temp_sample$sample_name),"WS",temp_sample$sample_matrix_code)
  temp_sample$sample_type_code <- ifelse(grepl("-FB",temp_sample$sample_name),"N",temp_sample$sample_type_code)
  temp_sample$sample_source <- ifelse(grepl("-FB",temp_sample$sample_name),"Field",temp_sample$sample_source)
  # Recode sample_source field for MS and MSDs as "Lab" instead of "Field" to be consistent with ALS data
  temp_sample$sample_source <- ifelse(grepl("MS|MSD",temp_sample$sample_type_code),"Lab",temp_sample$sample_source)

  
  ##### Locate and code QAQC samples #####
    
  # Set Site ID to 00-QAQC-0.0 for internal lab samples
  temp_sample$SITE_ID <- ifelse(temp_sample$sample_source %in% "Lab", "00-QAQC-0.0", temp_sample$SITE_ID)
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_source %in% "Lab", "LAB_INTERNAL", NA)
  

  # Populate DEC_sample_type for EB samples.
  # temp_sample$DEC_sample_type <- ifelse(grepl("-EB",temp_sample$sample_name),"EB", NA)

  # Populate DEC_sample_type for FB samples. (only used in Routine data, where mercury samples exist)
  temp_sample$DEC_sample_type <- ifelse(grepl("-FB",temp_sample$sample_name),"FB", temp_sample$DEC_sample_type)

  # Populate DEC_sample_type for duplicate samples.
      # Accounts for different DUP variants ("-DUP"", " DUP", "WSDUP", "WDUP", and upper/lowercase instances)
  # temp_sample$DEC_sample_type <- ifelse(grepl("-[Ss][Ee][Qq]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  # temp_sample$DEC_sample_type <- ifelse(grepl(" [Ss][Ee][Qq]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  # temp_sample$DEC_sample_type <- ifelse(grepl("WS[Ss][Ee][Qq]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  # temp_sample$DEC_sample_type <- ifelse(grepl("W[Ss][Ee][Qq]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  # temp_sample$DEC_sample_type <- ifelse(grepl("[Ss][Ee][Qq]_",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)
  
  # Populate DEC_sample_type for N_DUPPARENT cells by locating DUP samples and finding parent sample by removing DUP code. 
  # Updated 4/7/21 to perform on sys_sample_code instead of sample_name in case reanalyses present (was causing to fail).
  # dup.vec <- temp_sample$sys_sample_code[grepl("-[Ss][Ee][Qq]", temp_sample$sys_sample_code)]
  # parent.vec <- gsub("-[Ss][Ee][Qq]", "", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  # 
  # dup.vec <- temp_sample$sys_sample_code[grepl(" [Ss][Ee][Qq]", temp_sample$sys_sample_code)]
  # parent.vec <- gsub(" [Ss][Ee][Qq]", "", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  # 
  # dup.vec <- temp_sample$sys_sample_code[grepl("WS[Ss][Ee][Qq]", temp_sample$sys_sample_code)]
  # parent.vec <- gsub("WS[Ss][Ee][Qq]", "WS", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  # 
  # dup.vec <- temp_sample$sys_sample_code[grepl("W[Ss][Ee][Qq]", temp_sample$sys_sample_code)]
  # parent.vec <- gsub("W[Ss][Ee][Qq]", "W", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  # 
  # dup.vec <- temp_sample$sys_sample_code[grepl("[Ss][Ee][Qq]_", temp_sample$sys_sample_code)]
  # parent.vec <- gsub("[Ss][Ee][Qq]_", "_", dup.vec)
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sys_sample_code %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)

  # Identify internal lab samples in DEC_sample_type_field
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_matrix_code == "WQ" , "LAB_INTERNAL", temp_sample$DEC_sample_type)
  # Identify trib blanks (Mohawk 2019) in DEC_sample_type field
  # temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_type_code == "TB", "TB", temp_sample$DEC_sample_type)
  
  # Populate remaining DEC_sample_type NAs for field data with "N" for normal samples (assumes all remaining NAs are normal samples).
  temp_sample$DEC_sample_type <- ifelse(is.na(temp_sample$DEC_sample_type),"N",temp_sample$DEC_sample_type)

  # Count number of each FIELD sample type identified and print
  count.Normal <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("^N$", temp_sample$DEC_sample_type)])  
  message(paste0(count.Normal," N"))
  
  count.N_DUPPARENT <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("N_DUPPARENT", temp_sample$DEC_sample_type)])  
  message(paste0(count.N_DUPPARENT," N_DUPPARENT"))
  
  count.DUP <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("^DUP$", temp_sample$DEC_sample_type)])  
  message(paste0(count.DUP," DUP"))
  
  count.EB <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("^EB$", temp_sample$DEC_sample_type)])  
  message(paste0(count.EB," EB"))
  
  count.FB <- length(temp_sample$DEC_sample_type[temp_sample$sample_source == "Field" & grepl("^FB$", temp_sample$DEC_sample_type)])  
  message(paste0(count.FB," FB\n"))
  
  # count.MS <- length(grep("^MS$", temp_sample$sample_type_code))  
  # message(paste0(count.MS," MS (including lab MSs)\n"))
  
  # Check if equal number of DUP and N_DUPPARENT codes assigned. Stop script if not.
  if(identical(count.DUP,count.N_DUPPARENT) == FALSE){
    stop("    DUP and N_DUPPARENT counts do not match (script stopped)")
  }
    
  ##### Merge sample and result files #####
    # Must merge by sys_sample_code and not sample_name in order to appropriately associate MS, dissolved samples (sometimes "Diss" or "S" added to end of sys_sample_code), and other lab samples with appropriate results.
  
  temp_RSmerge <- merge(temp_sample,temp_result,by="sys_sample_code", all=TRUE)

  filenm <- file.path(output.i,
                      paste(folder_list[i],"_RSmerge.csv", sep=""))

  if ((nrow(temp_result)) < (nrow(temp_RSmerge))) {
    stop('SCRIPT STOPPED: Extra records created in merge. Check EDD for errors.')
  }
  if ((nrow(temp_result)) > (nrow(temp_RSmerge))) {
    stop('SCRIPT STOPPED: Not enough records created with merge. Check for errors.')
  }

  # Create name using EDD and added suffix, and assign to current data frame
  mergenm <- paste0(folder_list[i], "_RSmerge")
  mergefile <- assign(mergenm, temp_RSmerge)
  
  # Do the same for sample and result file data (used for assessing samples present and counting sample totals)
  mergenm.sample <- paste0(folder_list[i], "_Samplemerge")
  mergefile.sample <- assign(mergenm.sample, temp_sample)
  mergenm.result <- paste0(folder_list[i], "_Resultmerge")
  mergefile.result <- assign(mergenm.result, temp_result)
  # mergenm.batch <- paste0(folder_list[i], "_Batchmerge")
  # mergefile.batch <- assign(mergenm.batch, temp_batch)
  
  #Add current data frame to the list of all dataframes
  RSfile_list[[i]] <- mergefile
  sample.file_list[[i]] <- mergefile.sample
  result.file_list[[i]] <- mergefile.result
  # batch.file_list[[i]] <- mergefile.batch
  
  rm(mergefile, mergefile.sample, mergefile.result)
  
  # Export each merged EDD as CSVs (use for troubleshooting)
  # write.table(temp_RSmerge, file=filenm,sep=",", row.names = FALSE)
}

#Bind all data frames (merged sample-result files) into one
RIBSdata.ALL = do.call(rbind, RSfile_list)
RIBSdata.sample = do.call(rbind, sample.file_list)
RIBSdata.result = do.call(rbind, result.file_list)
# RIBSdata.batch = do.call(rbind, batch.file_list)

# Move new Site ID and DEC Sample Type columns to beginning of data frame
RIBSdata.ALL <- RIBSdata.ALL %>% 
  select(SITE_ID, DEC_sample_type, everything())
RIBSdata.sample <- RIBSdata.sample %>% 
  select(SITE_ID, DEC_sample_type, everything())


# List unqique sampling dates to verify all present
sample.dates <- unique(as.Date(RIBSdata.sample$sample_date[RIBSdata.sample$sample_source == "Field"], "%m/%d/%Y %H:%M:%S"))
# sample.dates <- unique(as.Date(RIBSdata.sample$sample_date[RIBSdata.sample$sample_source == "Field"], "%Y-%m-%d %H:%M:%S"))
message(paste0(length(sample.dates)," unique sample dates present:\n"))
cat(as.character(sort(sample.dates)), sep = "\n")



### Summarize sample counts to compare to COCs (ensure sure all codes assigned appropriately).
# Rebuilt code code block below when expanded code assignments to lab samples

totalcount.Normal <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("^N$", RIBSdata.sample$DEC_sample_type)])
totalcount.DUP <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("^DUP$", RIBSdata.sample$DEC_sample_type)])
totalcount.N_DUPPARENT <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("N_DUPPARENT", RIBSdata.sample$DEC_sample_type)])
totalcount.EB <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("^EB$", RIBSdata.sample$DEC_sample_type)])
totalcount.FB <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Field" & grepl("^FB$", RIBSdata.sample$DEC_sample_type)])     # FB only present in Routine Network data
totalcount.MS <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Lab" & RIBSdata.sample$sample_type_code == "MS"]) 
totalcount.MSD <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Lab" & RIBSdata.sample$sample_type_code == "SD"]) 
totalcount.LR <- length(RIBSdata.sample$DEC_sample_type[RIBSdata.sample$sample_source == "Lab" & RIBSdata.sample$sample_type_code == "LR"]) 

message(paste0("\nTotal samples identified (+1 for each subcontracted sample :)\n", 
               totalcount.Normal, " N\n", 
               totalcount.N_DUPPARENT, " N_DUPPARENT\n", 
               totalcount.DUP, " DUP\n",  
               totalcount.EB, " EB\n", 
               totalcount.FB, " FB (should only be present for Routine)\n" ,
               totalcount.MS, " Matrix Spikes (not run on all params for all samples)\n",
               totalcount.MSD, " Matrix Spike Dups\n",
               totalcount.LR, " Lab replicates\n"
               ))

if(totalcount.DUP == 0){warning(paste0("    WARNING: NO DUPLICATES PRESENT\n"))}
if(totalcount.N_DUPPARENT == 0){warning(paste0("    WARNING: NO DUP PARENTS PRESENT\n"))}
if(totalcount.EB == 0){warning(paste0("    WARNING: NO EBs PRESENT\n"))}
if(totalcount.FB == 0){warning(paste0("    WARNING: NO FBs PRESENT (only required for Routine data)\n"))}
# if(totalcount.FB > 0){warning(paste0("    WARNING: FBs PRESENT (only should be present for Routine data)\n"))}
if(totalcount.MS == 0){warning(paste0("    WARNING: NO MSs PRESENT\n"))}

# Check for ALS reanalyses (could mean duplicate results for one sample/param combination)
reanalyses <- RIBSdata.ALL$sys_sample_code[(endsWith(RIBSdata.ALL$sys_sample_code,"RE"))]
if(length(reanalyses) > 0){
  message("\nWARNING: Reanalyses present (possible duplicate results for one sample/param combination): \n\n",cat(reanalyses, sep = "\n"))
} 

```

See if matches for generated site IDs exist in master sites table. If mismatches are found, process into code for copy/pasting into next chunk for correcting. 2nd instance of each site ID (after the ~) to be corrected manually after pasting next chunk.
# Use RIBSdata.sample (sample list only) to help troubleshoot site ID mismatch issues.
# Use space at top of this chunk if edits needed before matching site IDs
```{r echo=TRUE}
########################


# List unique site IDs generated and creat match/mismatch lists
siteids.present <- unique(RIBSdata.ALL$SITE_ID[!is.na(RIBSdata.ALL$SITE_ID)])
siteids.mismatch <- siteids.present[!(siteids.present %in% sites.master$SITE_ID)]
siteids.match <- siteids.present[(siteids.present %in% sites.master$SITE_ID)]

# See if mismatches exist. If so (else), prepare code for renaming mismatched site IDs and print to console to be pasted into the chunk below. 2nd instance of each site ID (after the ~) to be corrected manually after pasting in chunk below.
if (length(siteids.mismatch) == 0 & length(siteids.match) > 0) {
  message("Match found for all ", length(siteids.match), " site IDs.")
} else{
  message(length(siteids.present)," unique site IDs generated from sample IDs\n",length(siteids.match), " matches found, ", length(siteids.mismatch), " mismatch(es):\n")
  siteids.mismatch.code <- paste0("    SITE_ID == '",siteids.mismatch,"' ~ '",siteids.mismatch,"',")
  cat(siteids.mismatch.code,sep="\n")
}

# message("\n\nUnique site ID's present in sys_loc_code field (as transcribed by ALS)")
# sort(unique(RIBSdata.sample$sys_loc_code))

```

SITE_ID and data corrections:
Run as many times as needed until all corrected.
User manually corrects site IDs that couldn't be located in master sites table by pasting the output code from above and correct the 2nd instance of each site ID (after the ~).
```{r correct_data,echo=TRUE}
RIBSdata.ALL_corr <- RIBSdata.ALL %>% 
  mutate(SITE_ID_corr = case_when(
    SITE_ID == '00-QAQC-0.0' ~ '00-QAQC-0.0',
    SITE_ID == '02-CHAD-2.2' ~ '02-CHAD-1.9',
    SITE_ID == '10-SARA-0.4' ~ '10-SARA-0.3',
    SITE_ID == '13-ROND-9.9' ~ '13-ROND-9.2',

    TRUE ~ SITE_ID
  )
  ) %>% 
  mutate(SITE_ID_CORR_IND = if_else(SITE_ID_corr == SITE_ID, "N", "Y")) %>% 
  select(-SITE_ID) %>% 
  select(SITE_ID_corr, SITE_ID_CORR_IND, everything()) %>% 
  rename(SITE_ID = SITE_ID_corr)

# Do the same for the sample file

RIBSdata.sample_corr <- RIBSdata.sample %>% 
  mutate(SITE_ID_corr = case_when(
    SITE_ID == '00-QAQC-0.0' ~ '00-QAQC-0.0',
    SITE_ID == '02-CHAD-2.2' ~ '02-CHAD-1.9',
    SITE_ID == '10-SARA-0.4' ~ '10-SARA-0.3',
    SITE_ID == '13-ROND-9.9' ~ '13-ROND-9.2',

    TRUE ~ SITE_ID
    )
  ) %>% 
  mutate(SITE_ID_CORR_IND = if_else(SITE_ID_corr == SITE_ID, "N", "Y")) %>% 
  select(-SITE_ID) %>% 
  select(SITE_ID_corr, SITE_ID_CORR_IND, everything()) %>% 
  rename(SITE_ID = SITE_ID_corr)
  
# Check again for mismatches and print
siteids.present.corr <- unique(RIBSdata.ALL_corr$SITE_ID[!is.na(RIBSdata.ALL_corr$SITE_ID)])
siteids.mismatch2 <- siteids.present.corr[!(siteids.present.corr %in% sites.master$SITE_ID)]
siteids.match2 <- siteids.present.corr[(siteids.present.corr %in% sites.master$SITE_ID)]

if(length(siteids.mismatch2 > 0)){
  message("The following ", length(siteids.mismatch2), " sites were still not matched:")
  cat(siteids.mismatch2,sep="\n")
} else{
  message("All sites matched!")
}
```

```{r Completeness check}

# Apply project names based on SDG
joblist <- read_excel(file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - ALS/2021/kelso/job_list", "dec_kelso_joblist.xlsx")) %>% 
  select(sample_delivery_group, Project, Team)

# Return missing EDDs from project list
joblist.missing <- joblist %>% 
  filter(!sample_delivery_group %in% RIBSdata.sample$sample_delivery_group)

sample.proj <- RIBSdata.sample_corr %>% 
  left_join(joblist) %>% 
  select(Project, Team, everything()) %>% 
  filter(sample_source %in% "Field")

sample.ribs <- sample.proj %>% 
  filter(grepl("Routine", Project))
sample.meth <- sample.proj %>% 
  filter(grepl("Methods", Project))

k.2019 <- sample.ribs %>% 
  filter(grepl("2019", sample_date),
         # sample_source %in% "Field",
         DEC_sample_type %in% "N") 

k.2021apr <- sample.ribs %>% 
  filter(!grepl("2019", sample_date),
         grepl("04/", sample_date),
         # sample_source %in% "Field",
         DEC_sample_type %in% "N")  

k.2021aug <- sample.ribs %>% 
  filter(!grepl("2019", sample_date),
         grepl("08/", sample_date),
         # sample_source %in% "Field",
         DEC_sample_type %in% "N")  

# Return missing sites from 2021 sampling
k.2021apr.missing <- sites.routine %>% 
  filter(!SITE_ID %in% k.2021apr$SITE_ID)
k.2021aug.missing <- sites.routine %>% 
  filter(!SITE_ID %in% k.2021aug$SITE_ID)
```


Write final tables to CSV (Remember to copy report or Rmd to output dir)
```{r}

# Apply project names based on SDG
joblist <- read_excel(file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - ALS/2021/kelso/job_list", "dec_kelso_joblist.xlsx")) %>% 
  select(sample_delivery_group, Project, Team)

RIBSdata.ALL_corr.proj <- RIBSdata.ALL_corr %>% 
  left_join(joblist) %>% 
  select(Project, Team, everything()) 
  # filter(sample_source %in% "Field")

# Check job list against data for missing EDDs
k.missing <- joblist %>% 
  select(sample_delivery_group, Project) %>% 
  filter(!sample_delivery_group %in% RIBSdata.ALL_corr.proj$sample_delivery_group)
# Missing K2103837 (analysis canceled due to resampling needed) and K2109730 (not yet received)

RIBSdata.meth_eval <- RIBSdata.ALL_corr.proj %>% 
  filter(Project %in% "CEC Methods Eval")

# Manually check methods eval data for missing sites
# > sort(unique(RIBSdata.meth_eval$SITE_ID))
# [1] "10-BOQT-2.6"   "10-SABL-14.6"  "10-SARA-0.3"   "11-UHUD-267.8" "11-UHUD-42.5"  "13-LHUD-125.8" "13-ROND-9.2"   "13-WALK-18.6"  "17-BRNX-5.6" 
# # Mohawk is missing (EDD K2109730)

RIBSdata.routine_cec <- RIBSdata.ALL_corr.proj %>% 
  filter(grepl("*Routine", Project))

# # Export sample table
# write.table(RIBSdata.sample_corr.proj, file= paste0(output.path,"/",output.sample.filename),sep=",", row.names = FALSE)
# 
# # Export results table
# write.table(RIBSdata.result, file= paste0(output.path,"/",output.result.filename),sep=",", row.names = FALSE)
# 
# # Export batch table
# write.table(RIBSdata.batch, file= paste0(output.path,"/",output.batch.filename),sep=",", row.names = FALSE)

# Export pre-joined tables (for running through QAQC script)
write.csv(RIBSdata.routine_cec, file.path("C:/Users/gmlemley/New York State Office of Information Technology Services/BWAM - CECs/data/ppcp", "routine_ppcp_results_2019_2021.csv"),row.names = FALSE)


# Export sample and batch (all data) for adding to database
# # Export sample table
# write.table(RIBSdata.sample_corr.proj, file= paste0(output.path,"/",output.sample.filename),sep=",", row.names = FALSE)
# 
# # Export results table
# write.table(RIBSdata.result, file= paste0(output.path,"/",output.result.filename),sep=",", row.names = FALSE)


```

