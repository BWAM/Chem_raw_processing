---
title: "RIBS_EDD_processing"
author: "Gavin Lemley"
date: "January 11, 2019"
output: html_document
---

## R Markdown

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = FALSE)
```

Load libraries, find the R-project root directory, and specify input/output files.
```{r}
library(dplyr)
root.dir <- rprojroot::find_root("Chem_raw_processing.Rproj")

##### User-defined variables #####

# DO NOT RUN FULL SCRIPT. MUST RUN CHUNK-BY-CHUNK AND CORRECT SITE IDs AND DATA WHERE NEEDED #
input.path <- file.path(root.dir, "data_input", "2018", "Wallkill")
output.path <- file.path(root.dir, "data_output", "2018", "Wallkill")
output.filename <- "2018_Wallkill_chem_raw_3-26-19.csv"
# DO NOT RUN FULL SCRIPT. MUST RUN CHUNK-BY-CHUNK AND CORRECT SITE IDs AND DATA WHERE NEEDED #

##################################

```

Main process: 
1) Loads in EDD components from each folder contained in the target directory. 
2) Adds SiteID and DEC_sample_type fields to each Sample_v3.
3) Merges TestResultQC_v3 and Sample_v3 files together for each EDD set.
```{r}

# folder_list <- list.files(path = file.path(root.dir, "data_input", "2018", "Ramapo"))
folder_list <- list.files(path = input.path)
nfolder_list = length(folder_list)
RSfile_list <- list()
RSfile_list.sample <- list()

i=1
for (i in 1:nfolder_list){
  print(folder_list[i])
  # input.i <- file.path(root.dir, "data_input", "2018", "Ramapo", folder_list[i])
  input.i <- paste0(input.path, "/", folder_list[i])
  output.i <- file.path(root.dir, "data_output")
  
  temp_result <- read.table(file.path(input.i,"TestResultQC_v3.txt"),
                                      sep=",",fill=TRUE,header=FALSE,stringsAsFactors=FALSE,
                    col.names = c("sys_sample_code","lab_anl_method_name","analysis_date","fraction","column_number",
                                  "test_type","lab_matrix_code","analysis_location","basis","container_id","dilution_factor",
                                  "prep_method","prep_date","leachate_method","leachate_date","lab_name_code","qc_level",
                                  "lab_sample_id","percent_moisture","subsample_amount","subsample_amount_unit","analyst_name",
                                  "instrument_id","comment","preservative","final_volume","final_volume_unit","cas_rn","chemical_name",
                                  "result_value","result_error_delta","result_type_code","reportable_result","detect_flag",
                                  "lab_qualifiers","validator_qualifiers","interpreted_qualifiers","validated_yn",
                                  "method_detection_limit","reporting_detection_limit","quantitation_limit","result_unit",
                                  "detection_limit_unit","tic_retention_time","minimum_detectable_conc","counting_error","uncertainty",
                                  "critical_value","validation_level","result_comment","qc_original_conc","qc_spike_added",
                                  "qc_spike_measured","qc_spike_recovery","qc_dup_original_conc","qc_dup_spike_added",
                                  "qc_dup_spike_measured","qc_dup_spike_recovery","qc_rpd","qc_spike_lcl","qc_spike_ucl","qc_rpd_cl",
                                  "qc_spike_status","qc_dup_spike_status","qc_rpd_status","lab_sdg"),
                    colClasses = c(fraction="character")
                    )
 
  temp_sample <- read.table(file.path(input.i,"Sample_v3.txt"),
                            sep=",",fill=TRUE,header=FALSE, stringsAsFactors=FALSE,
                    col.names = c("#data_provider","sys_sample_code","sample_name","sample_matrix_code","sample_type_code",
                                  "sample_source","parent_sample_code","sample_delivery_group","sample_date","sys_loc_code",
                                  "start_depth","end_depth","depth_unit","chain_of_custody","sent_to_lab_date","sample_receipt_date",
                                  "sampler","sampling_company_code","sampling_reason","sampling_technique","task_code",
                                  "collection_quarter","composite_yn","composite_desc","sample_class","custom_field_1","custom_field_2",
                                  "custom_field_3","comment"))

  ### Creating new fields: SiteID and DEC_sample_type ###
  
  # Generate site IDs for field data by pulling info from sample_name before 3rd "-".
  temp_sample$SiteID <- ifelse(temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N", 
                               sub("^(([^-]*-){2}[^-]*).*","\\1" , temp_sample$sample_name), NA)
  # Generate DEC_sample_type column and and populate with EB code as needed.
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N" &
                                          grepl("EB",temp_sample$sample_name),"EB", NA)
  # Populate DEC_sample_type for duplicate samples as needed.
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N" &
                                          grepl("[Dd][Uu][Pp]",temp_sample$sample_name),"DUP",temp_sample$DEC_sample_type)

    
  # Populate DEC_sample_type for N_DUPPARENT cells by locating DUP samples and finding parent sample. 
      # Accounts for different DUP variants (" DUP"", "-DUP", "WSDUP", "WDUP", and upper/lowercase instances)

  dup.vec <- temp_sample$sample_name[temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N" 
                                     & grepl(" [Dd][Uu][Pp]", temp_sample$sample_name)]
  parent.vec <- gsub(" [Dd][Uu][Pp]", "", dup.vec)
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N" 
                                         & temp_sample$sample_name %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  
  dup.vec <- temp_sample$sample_name[temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N"
                                     & grepl("-[Dd][Uu][Pp]", temp_sample$sample_name)]
  parent.vec <- gsub("-[Dd][Uu][Pp]", "", dup.vec)
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N" 
                                         & temp_sample$sample_name %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  
  dup.vec <- temp_sample$sample_name[temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N"
                                     & grepl("WS[Dd][Uu][Pp]", temp_sample$sample_name)]
  parent.vec <- gsub("WS[Dd][Uu][Pp]", "WS", dup.vec)
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N"
                                         & temp_sample$sample_name %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  
  dup.vec <- temp_sample$sample_name[temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N"
                                     & grepl("W[Dd][Uu][Pp]", temp_sample$sample_name)]
  parent.vec <- gsub("W[Dd][Uu][Pp]", "W", dup.vec)
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N"
                                         & temp_sample$sample_name %in% parent.vec,"N_DUPPARENT",temp_sample$DEC_sample_type)
  
  
  # Count number of each sample type and print
  count.Normal <- length(grep("^N$", temp_sample$DEC_sample_type))
  message(paste0(count.Normal," N"))
  count.DUP <- length(grep("^DUP$", temp_sample$DEC_sample_type))
  message(paste0(count.DUP," DUP"))
  count.N_DUPPARENT <- length(grep("N_DUPPARENT", temp_sample$DEC_sample_type))
  message(paste0(count.N_DUPPARENT," N_DUPPARENT"))
  count.EB <- length(grep("^EB$", temp_sample$DEC_sample_type))
  message(paste0(count.EB," EB"))
  count.FB <- length(grep("^FB$", temp_sample$DEC_sample_type))     # FB only present in Routine Network data
  message(paste0(count.FB," FB"))
  count.MS <- length(grep("^MS$", temp_sample$sample_type_code))  
  message(paste0(count.MS," MS (including lab MSs)\n"))
  
    # Ensure equal number of DUP and N_DUPPARENT codes assigned
  if(identical(count.DUP,count.N_DUPPARENT) == FALSE){
    stop("    DUP and N_DUPPARENT counts do not match (script stopped)")
  }

  # Populate remaining DEC_sample_type cells for field data with "N" for normal samples.
  temp_sample$DEC_sample_type <- ifelse(temp_sample$sample_source == "Field" & temp_sample$sample_type_code == "N" &
                                          is.na(temp_sample$DEC_sample_type),"N",temp_sample$DEC_sample_type)

  # Convert all NAs in temp_sample$DEC_sample_type to avoid subsetting issues in QAQC script (found that bracket subsetting in a column that contains NAs returns NA rows)
  temp_sample$DEC_sample_type[is.na(temp_sample$DEC_sample_type)] <- "Lab"
  
  # Must merge by sys_sample_code and not sample_name in order to appropriately associate MS, dissolved samples (sometimes "Diss" or "S" added to end of sys_sample_code), and other lab samples with appropriate results.
  temp_RSmerge <- merge(temp_result,temp_sample,by="sys_sample_code", all=TRUE)

  filenm <- file.path(output.i,
                      paste(folder_list[i],"_RSmerge.csv", sep=""))

  if ((nrow(temp_result)) < (nrow(temp_RSmerge))) {
    stop('SCRIPT STOPPED: Extra records created in merge. Check EDD for errors.')
  }
  if ((nrow(temp_result)) > (nrow(temp_RSmerge))) {
    stop('SCRIPT STOPPED: Not enough records created with merge. Check for errors.')
  }

  # Create name using EDD and added suffix, and assign to current data frame
  mergenm <- paste0(folder_list[i], "_RSmerge")
  mergefile <- assign(mergenm, temp_RSmerge)
  
  # Do the same for only sample file data (used for counting sample totals)
  mergenm.sample <- paste0(folder_list[i], "_Samplemerge")
  mergefile.sample <- assign(mergenm, temp_sample)

  #Add current data frame to the list of all dataframes
  RSfile_list[[i]] <- mergefile
  RSfile_list.sample[[i]] <- mergefile.sample

  # Export each merged EDD as CSVs (optional)
  # write.table(temp_RSmerge, file=filenm,sep=",", row.names = FALSE)
}

#Bind all data frames (merged sample-result files) into one
RIBSdata = do.call(rbind, RSfile_list)
RIBSdata.sample = do.call(rbind, RSfile_list.sample)

### Summarize sample counts to compare to COCs (ensure sure all codes assigned appropriately).
totalcount.Normal <- length(grep("^N$", RIBSdata.sample$DEC_sample_type))
totalcount.DUP <- length(grep("^DUP$", RIBSdata.sample$DEC_sample_type))
totalcount.N_DUPPARENT <- length(grep("N_DUPPARENT", RIBSdata.sample$DEC_sample_type))
totalcount.EB <- length(grep("^EB$", RIBSdata.sample$DEC_sample_type))
totalcount.FB <- length(grep("^FB$", RIBSdata.sample$DEC_sample_type))     # FB only present in Routine Network data
totalcount.MS <- length(grep("^MS$", RIBSdata.sample$sample_type_code))  

message(paste0("Total sample counts:\n", totalcount.Normal, " N\n",totalcount.DUP, " DUP\n", totalcount.N_DUPPARENT, " N_DUPPARENT\n", totalcount.EB, " EB\n", totalcount.FB, " FB\n", totalcount.MS, " MS (including lab MSs)\n"))

if(totalcount.DUP == 0){warning(paste0("    WARNING: NO DUPLICATES PRESENT"))}
if(totalcount.N_DUPPARENT == 0){warning(paste0("    WARNING: NO DUP PARENTS PRESENT"))}
if(totalcount.EB == 0){warning(paste0("    WARNING: NO EBs PRESENT"))}
if(totalcount.FB == 0){warning(paste0("    WARNING: NO FBs PRESENT (only required for Routine Network data)"))}
if(totalcount.MS == 0){warning(paste0("    WARNING: NO MSs PRESENT"))}
 
```

See if matches for generated site IDs exist in master sites table. If mismatches are found, process into code for copy/pasting into next chunk for correcting. 2nd instance of each site ID (after the ~) to be corrected manually after pasting next chunk.
```{r}
sites.master <- read.csv("data_input/Sites_2017-2018_Charlie.csv")
# sites.master <- read.csv("data_input/Sites_2018-12-17_Di.csv")

#Create BAS_LOC_RM field
#Format fields to add leading, and keep trailing zeros.
sites.master$BASIN <- formatC(sites.master$BASIN, width = 2, format = "d", flag = "0")
#Issue with sites that use "001" as rivermile. 001 will read into R as "1" and will therefore be reformatted to "1.0".
sites.master$RIVMILE <- formatC( sites.master$RIVMILE, format='f', digits=1 )

#Create BAS_LOC_RM field

sites.master$BAS_LOC_RM <- ifelse(!is.na(sites.master$BASIN) & !is.na(sites.master$LOCATION) & !is.na(sites.master$RIVMILE),
       paste0(sites.master$BASIN,"-",sites.master$LOCATION,"-",sites.master$RIVMILE),NA)

siteids.present <- unique(RIBSdata$SiteID[!is.na(RIBSdata$SiteID)])

siteids.mismatch <- siteids.present[!(siteids.present %in% sites.master$BAS_LOC_RM)]
siteids.match <- siteids.present[(siteids.present %in% sites.master$BAS_LOC_RM)]

# See if mismatches exist. If so (else), prepare code for renaming mismatched site IDs and print to console to be pasted into the chunk below. 2nd instance of each site ID (after the ~) to be corrected manually after pasting in chunk below.
if (length(siteids.mismatch) == 0 & length(siteids.match) > 0) {
  message("Match found for all ", length(siteids.match), " site IDs.")
} else{
  message(length(siteids.match), " sites matched, ", length(siteids.mismatch), " NOT matched:\n")
  siteids.mismatch.code <- paste0("    SiteID == '",siteids.mismatch,"' ~ '",siteids.mismatch,"',")
  cat(siteids.mismatch.code,sep="\n")
}

```

######
SiteID and data corrections:
Run if matches not found for all site IDs found in master sites table (chunk above), or other data corrections needed.
User manually corrects site IDs that couldn't be located in master sites table by pasting the output code from above and correct the 2nd instance of each site ID (after the ~).
######

```{r correct_data,echo=TRUE}
RIBSdata.siteids.corr <- RIBSdata %>% 
  mutate(SiteID = case_when(
    SiteID == '07-ONID-XX' ~ '07-ONID-4.0',
    TRUE ~ SiteID
    )
)

### Enter other data corrections here:

# (KEEP THIS CODE COMMENTED HERE AS AN EXAMPLE)
# Ramapo: There were several 'fraction' values for aluminum that should have been D for dissolved and not T.
# RIBSdata.siteids.corr <- RIBSdata.siteids.corr %>%
#   mutate(fraction = case_when(
#     chemical_name == 'Aluminum' & fraction == 'T' ~ 'D',
#     TRUE ~ fraction
#   )
# )

# Check again for mismatches and print
siteids.present.corr <- unique(RIBSdata.siteids.corr$SiteID[!is.na(RIBSdata.siteids.corr$SiteID)])
siteids.mismatch2 <- siteids.present.corr[!(siteids.present.corr %in% sites.master$BAS_LOC_RM)]
siteids.match2 <- siteids.present.corr[(siteids.present.corr %in% sites.master$BAS_LOC_RM)]
cat(siteids.mismatch2,sep="\n")
```

Write dataset to CSV. (Remember to knit and copy HTML report to output dir)
```{r}

# Manualy copy to L:\DOW\SMAS\StreamDatabase\Chemistry\raw_merge-bind\[year]\. Automate this after L drive is reorganized.

if(exists("RIBSdata.siteids.corr")){
  write.table(RIBSdata.siteids.corr, file= paste0(output.path,"/",output.filename),sep=",", row.names = FALSE)
} else {
  write.table(RIBSdata, file= paste0(output.path,"/",output.filename),sep=",", row.names = FALSE)
}

# write.table(RIBSdata.sample, file= file.path(root.dir, "data_output", "2018_Ramapo_SAMPLE_merge-bind_2-12-19.csv"),sep=",", row.names = FALSE)

### Add step to append this data to a raw archive of ALS data? (And keep track of which projects have been run) ###
  # Use L:\DOW\SMAS\StreamDatabase\Chemistry\raw_merge-bind\[year]\


```

